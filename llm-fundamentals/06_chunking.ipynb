{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88c54409",
   "metadata": {},
   "source": [
    "## Chunking\n",
    "\n",
    "Chunking is the process of breaking down documents into smaller pieces that can be efficiently processed by language models and retrieval systems. The way you chunk your documents directly impacts :\n",
    "\n",
    "- **Retrieval Precision** : How accurately your system can find relevant information\n",
    "- **Context Preservation** : How much surrounding information is maintained\n",
    "- **Token Economy** : How efficiently you use your LLM's context window\n",
    "- **Storage Requirements** : How much vector storage you need\n",
    "\n",
    "Let's explore different chunking strategies and their impact on document retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3314b09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import Document\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "559af5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample document text\n",
    "sample_doc = \"\"\"\n",
    "# Introduction to Vector Databases\n",
    "\n",
    "Vector databases are specialized database systems designed to store and query vector embeddings efficiently.\n",
    "Unlike traditional databases optimized for exact matches, vector databases excel at similarity searches.\n",
    "\n",
    "## Key Advantages\n",
    "\n",
    "Vector databases offer several advantages for AI applications:\n",
    "- Efficient similarity search using algorithms like HNSW and IVF\n",
    "- Support for high-dimensional vector data\n",
    "- Optimized for retrieval-augmented generation (RAG) applications\n",
    "\n",
    "## Common Operations\n",
    "\n",
    "The most common operations in vector databases include:\n",
    "1. Adding vectors with associated metadata\n",
    "2. Searching for similar vectors using distance metrics\n",
    "3. Filtering results based on metadata\n",
    "4. Building and optimizing indexes for faster retrieval\n",
    "\n",
    "# Performance Considerations\n",
    "\n",
    "When working with vector databases at scale, consider:\n",
    "- Index construction time vs. query performance\n",
    "- Memory usage vs. search accuracy\n",
    "- Batch processing for efficient vector insertion\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2976f0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Document\n",
      " # Introduction to Vector Databases  Vector databases are specialized database systems\n",
      "designed to store and query vector embeddings efficiently. Unlike traditional databases\n",
      "optimized for exact matches, vector databases excel at similarity searches.  ## Key\n",
      "Advantages  Vector databases offer several advantages for AI applications: - Efficient\n",
      "similarity search using algorithms like HNSW and IVF - Support for high-dimensional vector\n",
      "data - Optimized for retrieval-augmented generation (RAG) applications  ## Common\n",
      "Operations  The most common operations in vector databases include: 1. Adding vectors with\n",
      "associated metadata 2. Searching for similar vectors using distance metrics 3. Filtering\n",
      "results based on metadata 4. Building and optimizing indexes for faster retrieval  #\n",
      "Performance Considerations  When working with vector databases at scale, consider: - Index\n",
      "construction time vs. query performance - Memory usage vs. search accuracy - Batch\n",
      "processing for efficient vector insertion\n"
     ]
    }
   ],
   "source": [
    "# Create a Document\n",
    "document = Document(text=sample_doc)\n",
    "\n",
    "print(\"Original Document\")\n",
    "print(textwrap.fill(document.text, 90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9930f4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata length (0) is close to chunk size (40). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "# Sentence-based chunking\n",
    "sentence_splitter = SentenceSplitter(chunk_size=40, chunk_overlap=10)\n",
    "\n",
    "sentence_nodes = sentence_splitter.get_nodes_from_documents([document])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "542652fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence chunks created : 6\n",
      "- Chunk n°1 :\n",
      "# Introduction to Vector Databases  Vector databases are specialized database systems designed to\n",
      "store and query vector embeddings efficiently. Unlike traditional databases optimized for exact\n",
      "matches, vector databases excel at similarity searches.  ## Key\n",
      "Characters length : 257\n",
      "\n",
      "- Chunk n°2 :\n",
      "## Key Advantages  Vector databases offer several advantages for AI applications: - Efficient\n",
      "similarity search using algorithms like HNSW and IVF - Support for high-dimensional vector data -\n",
      "Optimized for\n",
      "Characters length : 205\n",
      "\n",
      "- Chunk n°3 :\n",
      "for high-dimensional vector data - Optimized for retrieval-augmented generation (RAG) applications\n",
      "## Common Operations  The most common operations in vector databases include: 1.\n",
      "Characters length : 180\n",
      "\n",
      "- Chunk n°4 :\n",
      "common operations in vector databases include: 1. Adding vectors with associated metadata 2.\n",
      "Searching for similar vectors using distance metrics 3. Filtering results based on metadata 4.\n",
      "Characters length : 187\n",
      "\n",
      "- Chunk n°5 :\n",
      "Filtering results based on metadata 4. Building and optimizing indexes for faster retrieval  #\n",
      "Performance Considerations  When working with vector databases at scale, consider: - Index\n",
      "construction time vs.\n",
      "Characters length : 207\n",
      "\n",
      "- Chunk n°6 :\n",
      "query performance - Memory usage vs. search accuracy - Batch processing for efficient vector\n",
      "insertion\n",
      "Characters length : 102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sentence chunks created : {len(sentence_nodes)}\")\n",
    "for i in range(len(sentence_nodes)):\n",
    "    print(f\"- Chunk n°{i + 1} :\")\n",
    "    print(f\"{textwrap.fill(sentence_nodes[i].text, 100)}\")\n",
    "    print(f\"Characters length : {len(sentence_nodes[i].text)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "849cfef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata length (2) is close to chunk size (40). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "\n",
    "# Token-based chunking\n",
    "token_splitter = TokenTextSplitter(chunk_size=40, chunk_overlap=10)\n",
    "token_nodes = token_splitter.get_nodes_from_documents([document])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c39e2a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token chunks created : 7\n",
      "- Chunk n°1 :\n",
      "# Introduction to Vector Databases  Vector databases are specialized database systems designed to\n",
      "store and query vector embeddings efficiently. Unlike traditional databases optimized for exact\n",
      "matches, vector databases excel at similarity\n",
      "Characters length : 239\n",
      "\n",
      "- Chunk n°2 :\n",
      "optimized for exact matches, vector databases excel at similarity searches.  ## Key Advantages\n",
      "Vector databases offer several advantages for AI applications: - Efficient similarity search using\n",
      "algorithms like HNSW and\n",
      "Characters length : 219\n",
      "\n",
      "- Chunk n°3 :\n",
      "Efficient similarity search using algorithms like HNSW and IVF - Support for high-dimensional vector\n",
      "data - Optimized for retrieval-augmented generation (RAG) applications  ## Common\n",
      "Characters length : 182\n",
      "\n",
      "- Chunk n°4 :\n",
      "generation (RAG) applications  ## Common Operations  The most common operations in vector databases\n",
      "include: 1. Adding vectors with associated metadata 2. Searching for similar vectors using distance\n",
      "Characters length : 199\n",
      "\n",
      "- Chunk n°5 :\n",
      "metadata 2. Searching for similar vectors using distance metrics 3. Filtering results based on\n",
      "metadata 4. Building and optimizing indexes for faster retrieval  # Performance Considerations  When\n",
      "working with\n",
      "Characters length : 208\n",
      "\n",
      "- Chunk n°6 :\n",
      "retrieval  # Performance Considerations  When working with vector databases at scale, consider: -\n",
      "Index construction time vs. query performance - Memory usage vs. search accuracy - Batch processing\n",
      "for\n",
      "Characters length : 201\n",
      "\n",
      "- Chunk n°7 :\n",
      "usage vs. search accuracy - Batch processing for efficient vector insertion\n",
      "Characters length : 75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Token chunks created : {len(token_nodes)}\")\n",
    "for i in range(len(token_nodes)):\n",
    "    print(f\"- Chunk n°{i + 1} :\")\n",
    "    print(f\"{textwrap.fill(token_nodes[i].text, 100)}\")\n",
    "    print(f\"Characters length : {len(token_nodes[i].text)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8ff2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import HierarchicalNodeParser\n",
    "\n",
    "# Hierarchical chunking\n",
    "hierarchical_parser = HierarchicalNodeParser.from_defaults(chunk_sizes=[70, 60, 40])\n",
    "hierarchical_nodes = hierarchical_parser.get_nodes_from_documents([document])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c51903a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hierarchica chunks created : 18\n",
      "- Chunk n°1 :\n",
      "# Introduction to Vector Databases  Vector databases are specialized database systems designed to\n",
      "store and query vector embeddings efficiently. Unlike traditional databases optimized for exact\n",
      "matches, vector databases excel at similarity searches.\n",
      "Characters length : 249\n",
      "\n",
      "- Chunk n°2 :\n",
      "## Key Advantages  Vector databases offer several advantages for AI applications: - Efficient\n",
      "similarity search using algorithms like HNSW and IVF - Support for high-dimensional vector data -\n",
      "Optimized for retrieval-augmented generation (RAG) applications  ## Common Operations  The most\n",
      "common operations in vector databases include: 1.\n",
      "Characters length : 337\n",
      "\n",
      "- Chunk n°3 :\n",
      "Adding vectors with associated metadata 2. Searching for similar vectors using distance metrics 3.\n",
      "Filtering results based on metadata 4. Building and optimizing indexes for faster retrieval  #\n",
      "Performance Considerations  When working with vector databases at scale, consider: - Index\n",
      "construction time vs. query performance - Memory usage vs.\n",
      "Characters length : 343\n",
      "\n",
      "- Chunk n°4 :\n",
      "query performance - Memory usage vs. search accuracy - Batch processing for efficient vector\n",
      "insertion\n",
      "Characters length : 102\n",
      "\n",
      "- Chunk n°5 :\n",
      "# Introduction to Vector Databases  Vector databases are specialized database systems designed to\n",
      "store and query vector embeddings efficiently. Unlike traditional databases optimized for exact\n",
      "matches, vector databases excel at similarity searches.\n",
      "Characters length : 249\n",
      "\n",
      "- Chunk n°6 :\n",
      "## Key Advantages  Vector databases offer several advantages for AI applications: - Efficient\n",
      "similarity search using algorithms like HNSW and IVF - Support for high-dimensional vector data -\n",
      "Optimized for retrieval-augmented generation (RAG) applications  ## Common Operations  The most\n",
      "common operations in\n",
      "Characters length : 308\n",
      "\n",
      "- Chunk n°7 :\n",
      "retrieval-augmented generation (RAG) applications  ## Common Operations  The most common operations\n",
      "in vector databases include: 1.\n",
      "Characters length : 131\n",
      "\n",
      "- Chunk n°8 :\n",
      "Adding vectors with associated metadata 2. Searching for similar vectors using distance metrics 3.\n",
      "Filtering results based on metadata 4. Building and optimizing indexes for faster retrieval  #\n",
      "Performance Considerations  When working with vector databases at scale, consider: - Index\n",
      "construction time vs.\n",
      "Characters length : 306\n",
      "\n",
      "- Chunk n°9 :\n",
      "query performance - Memory usage vs.\n",
      "Characters length : 36\n",
      "\n",
      "- Chunk n°10 :\n",
      "query performance - Memory usage vs. search accuracy - Batch processing for efficient vector\n",
      "insertion\n",
      "Characters length : 102\n",
      "\n",
      "- Chunk n°11 :\n",
      "# Introduction to Vector Databases  Vector databases are specialized database systems designed to\n",
      "store and query vector embeddings efficiently. Unlike traditional databases optimized for exact\n",
      "matches, vector databases excel at similarity searches.\n",
      "Characters length : 249\n",
      "\n",
      "- Chunk n°12 :\n",
      "## Key Advantages  Vector databases offer several advantages for AI applications: - Efficient\n",
      "similarity search using algorithms like HNSW and IVF - Support for high-dimensional vector data -\n",
      "Optimized for\n",
      "Characters length : 205\n",
      "\n",
      "- Chunk n°13 :\n",
      "like HNSW and IVF - Support for high-dimensional vector data - Optimized for retrieval-augmented\n",
      "generation (RAG) applications  ## Common Operations  The most common operations in\n",
      "Characters length : 179\n",
      "\n",
      "- Chunk n°14 :\n",
      "retrieval-augmented generation (RAG) applications  ## Common Operations  The most common operations\n",
      "in vector databases include: 1.\n",
      "Characters length : 131\n",
      "\n",
      "- Chunk n°15 :\n",
      "Adding vectors with associated metadata 2. Searching for similar vectors using distance metrics 3.\n",
      "Filtering results based on metadata 4.\n",
      "Characters length : 137\n",
      "\n",
      "- Chunk n°16 :\n",
      "Filtering results based on metadata 4. Building and optimizing indexes for faster retrieval  #\n",
      "Performance Considerations  When working with vector databases at scale, consider: - Index\n",
      "construction time vs.\n",
      "Characters length : 207\n",
      "\n",
      "- Chunk n°17 :\n",
      "query performance - Memory usage vs.\n",
      "Characters length : 36\n",
      "\n",
      "- Chunk n°18 :\n",
      "query performance - Memory usage vs. search accuracy - Batch processing for efficient vector\n",
      "insertion\n",
      "Characters length : 102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Hierarchica chunks created : {len(hierarchical_nodes)}\")\n",
    "for i in range(len(hierarchical_nodes)):\n",
    "    print(f\"- Chunk n°{i + 1} :\")\n",
    "    print(f\"{textwrap.fill(hierarchical_nodes[i].text, 100)}\")\n",
    "    print(f\"Characters length : {len(hierarchical_nodes[i].text)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b36b3e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import MarkdownNodeParser\n",
    "\n",
    "# Structure-aware chunking for Markdown\n",
    "markdown_parser = MarkdownNodeParser()\n",
    "markdown_nodes = markdown_parser.get_nodes_from_documents([document])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02204362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdpwn chunks created : 4\n",
      "- Chunk n°1 :\n",
      "# Introduction to Vector Databases  Vector databases are specialized database systems designed to\n",
      "store and query vector embeddings efficiently. Unlike traditional databases optimized for exact\n",
      "matches, vector databases excel at similarity searches.\n",
      "Characters length : 249\n",
      "\n",
      "- Chunk n°2 :\n",
      "## Key Advantages  Vector databases offer several advantages for AI applications: - Efficient\n",
      "similarity search using algorithms like HNSW and IVF - Support for high-dimensional vector data -\n",
      "Optimized for retrieval-augmented generation (RAG) applications\n",
      "Characters length : 255\n",
      "\n",
      "- Chunk n°3 :\n",
      "## Common Operations  The most common operations in vector databases include: 1. Adding vectors with\n",
      "associated metadata 2. Searching for similar vectors using distance metrics 3. Filtering results\n",
      "based on metadata 4. Building and optimizing indexes for faster retrieval\n",
      "Characters length : 271\n",
      "\n",
      "- Chunk n°4 :\n",
      "# Performance Considerations  When working with vector databases at scale, consider: - Index\n",
      "construction time vs. query performance - Memory usage vs. search accuracy - Batch processing for\n",
      "efficient vector insertion\n",
      "Characters length : 217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Markdpwn chunks created : {len(markdown_nodes)}\")\n",
    "for i in range(len(markdown_nodes)):\n",
    "    print(f\"- Chunk n°{i + 1} :\")\n",
    "    print(f\"{textwrap.fill(markdown_nodes[i].text, 100)}\")\n",
    "    print(f\"Characters length : {len(markdown_nodes[i].text)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61fd4106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb1838c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a local embedding model\n",
    "embedding_model = HuggingFaceEmbedding(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create vector stores with different chunking strategies (using local embeddings)\n",
    "sentence_index = VectorStoreIndex(sentence_nodes, embed_model=embedding_model)\n",
    "token_index = VectorStoreIndex(token_nodes, embed_model=embedding_model)\n",
    "hierarchical_index = VectorStoreIndex(hierarchical_nodes, embed_model=embedding_model)\n",
    "markdown_index = VectorStoreIndex(markdown_nodes, embed_model=embedding_model)\n",
    "\n",
    "# Query to test retrieval\n",
    "query = \"What are the top operations in vector databases ?\"\n",
    "\n",
    "# Get retrieval results\n",
    "sentence_result = sentence_index.as_retriever().retrieve(query)\n",
    "token_result = token_index.as_retriever().retrieve(query)\n",
    "hierarchical_result = hierarchical_index.as_retriever().retrieve(query)\n",
    "markdown_result = markdown_index.as_retriever().retrieve(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c0f88a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Sentence chunking result :\n",
      "common operations in vector databases include: 1. Adding vectors with associated metadata 2.\n",
      "Searching for similar vectors using distance metrics 3. Filtering results based on metadata 4.\n",
      "\n",
      "- Token chunking result :\n",
      "generation (RAG) applications  ## Common Operations  The most common operations in vector databases\n",
      "include: 1. Adding vectors with associated metadata 2. Searching for similar vectors using distance\n",
      "\n",
      "- Hierarchical chunking result :\n",
      "## Key Advantages  Vector databases offer several advantages for AI applications: - Efficient\n",
      "similarity search using algorithms like HNSW and IVF - Support for high-dimensional vector data -\n",
      "Optimized for retrieval-augmented generation (RAG) applications  ## Common Operations  The most\n",
      "common operations in vector databases include: 1.\n",
      "\n",
      "- Markdown chunking result :\n",
      "## Common Operations  The most common operations in vector databases include: 1. Adding vectors with\n",
      "associated metadata 2. Searching for similar vectors using distance metrics 3. Filtering results\n",
      "based on metadata 4. Building and optimizing indexes for faster retrieval\n"
     ]
    }
   ],
   "source": [
    "# Compare top results\n",
    "print(\"- Sentence chunking result :\")\n",
    "print(f\"{textwrap.fill(sentence_result[0].text, 100)}\")\n",
    "print()\n",
    "print(\"- Token chunking result :\")\n",
    "print(f\"{textwrap.fill(token_result[0].text, 100)}\")\n",
    "print()\n",
    "print(\"- Hierarchical chunking result :\")\n",
    "print(f\"{textwrap.fill(hierarchical_result[0].text, 100)}\")\n",
    "print()\n",
    "print(\"- Markdown chunking result :\")\n",
    "print(f\"{textwrap.fill(markdown_result[0].text, 100)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747ea7d8",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "1. **Chunk Size Trade-offs**: Smaller chunks allow for more precise retrieval but may lose context. Larger chunks preserve more context but might introduce noise and use more tokens from LLM's context window.\n",
    "\n",
    "2. **Overlap Between Chunks**: adding overlap ensures that sentences or ideas that cross chunk boundaries aren't lost, but increases storage requirements and can create duplicate information in retrieval.\n",
    "\n",
    "3. **Structure Awareness**: Domain-specific chunking that understands document structure (like markdown example) typically produces better results but requires more specialized processing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
